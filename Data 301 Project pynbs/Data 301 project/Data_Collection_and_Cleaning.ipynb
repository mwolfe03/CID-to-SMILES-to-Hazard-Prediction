{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNVN9BNEy1J6WBcY2YzyITy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Data Collection and Cleaning"],"metadata":{"id":"pEsrVGbWfvQX"}},{"cell_type":"markdown","source":["The challenge we wanted to face was determining potential hazards given only the SMILES representation of the target molecule. This meant that the only data we could use to compare our target molecule with the molecules in our model had to be extracted from the SMILES string. This ended up being the largest challenge of our project, and we believe were are project truely shines is in the data collection. This is where the bulk of our time and work went. While attempting to solve the problem we realized that it would be best create python files to help keep track of all of the logic. Our presentation Explains what is going on the best (https://docs.google.com/presentation/d/1mM9jVTphG-KGLMMnJ64jOobA0GGqeCZog6zPpdtnB7w/edit#slide=id.g27324927fda_0_110)."],"metadata":{"id":"gTQ0ot1yf0ta"}},{"cell_type":"markdown","source":["## Conversion of SMILES to groupings"],"metadata":{"id":"5ByYqPK0hL2e"}},{"cell_type":"markdown","source":["**sub_group_from_smiles.py**\n","\n","File that handles the conversion of Smiles strings to substituents"],"metadata":{"id":"C_QAsoGUgJoQ"}},{"cell_type":"code","source":["import ring_handling_w_rdkit as ring_handle\n","\n","\n","\n","def smiles_to_sub_groups(SMILES_string : str) -> tuple|bool:\n","    \"\"\"\n","    Input: SMILES_string smiles representation of a molecule in string format\n","    Output: tuple containing tuple of all subgroups of the given molecule at index 0,\n","            and tuple of all combinations of adjacent subgroups at index 1\n","    Ex Input: \"CC1=C(C(=CC=C1)[N+](=O)[O-])N\"\n","    Ex Output: \"(('0CCCCCC', 'C', '[N+]', '=O', '[O-]', 'N'), (('CCCCCC', 'C'), ('[N+]', 'CCCCCC'), ('[N+]', '=O'), ('[O-]', '[N+]'), ('N', 'CCCCCC')))\"\n","    Note: subgroups that represent rings will have \"0\" at index 0 as a marker\n","    \"\"\"\n","\n","    if type(SMILES_string) != str:\n","        print(\"SMILES_string is of wrong type\")\n","        return False\n","\n","    try:\n","        sub_group_index_list = subgroups_from_SMILES(SMILES_string)\n","        test_neighbors_dict = determine_group_neighbors(SMILES_string, sub_group_index_list)\n","        cleaned_dict = clean_subgroup_dict(test_neighbors_dict, SMILES_string)\n","        group_list = get_group_list(cleaned_dict)\n","        combination_groups = create_group_combinations(cleaned_dict)\n","\n","        return group_list, combination_groups\n","\n","    except ValueError:\n","        print(\"Invalid SMILES_string\")\n","        return False\n","\n","\n","\n","def subgroups_from_SMILES(SMILES_string: str) -> list:\n","    subgroup_index_list = []\n","    index_to_group_dict = {}\n","\n","    if \"1\" in SMILES_string:  # checks if there are any rings\n","        ring_indices_lists = ring_handle.ring_handling_rdkit(SMILES_string)\n","        index_to_group_dict = ring_handle.create_dict_of_ring_indices(ring_indices_lists)\n","        ring_num = 1\n","        for ring_indices in ring_indices_lists:\n","            subgroup_index_list.append((str(ring_num), ring_indices))\n","            ring_num += 1\n","\n","    bond_type_tuple = (\"=\", \"#\")\n","    grouping_type_tuple = (\"(\", \")\")\n","\n","    current_sub_group = []\n","    current_group_ascii = 97\n","    current_group_name = chr(current_group_ascii)\n","\n","    SMILES_length = len(SMILES_string)\n","    for i in range(SMILES_length):\n","        char = SMILES_string[i]\n","        if i in index_to_group_dict:\n","            # With the exception of rings, no atom/bond index should appear in more than one group.\n","            # An atom/bond index can be in 1 group OR in 1 or more rings\n","            # everything before this should be its own group\n","            if len(current_sub_group) > 0:\n","                current_group_ascii += 1\n","                current_group_name = chr(current_group_ascii)\n","                subgroup_index_list.append((current_group_name, current_sub_group))\n","            current_sub_group = []\n","            continue\n","\n","        elif char.isdigit():\n","            # no reason to include digits\n","            # everything before this should be its own group\n","            # in theory, current_sub_group should always be a list of len 0 here\n","            if len(current_sub_group) > 0:\n","                current_group_name = chr(current_group_ascii)\n","                subgroup_index_list.append((current_group_name, current_sub_group))\n","                current_group_ascii += 1\n","                current_group_name = chr(current_group_ascii)\n","            current_sub_group = []\n","            continue\n","\n","        elif char in grouping_type_tuple:\n","            if char == \"(\":\n","                current_sub_group.append(i)  # including opening now helps with finding neighbors later\n","            # leaves as list for now\n","            subgroup_index_list.append((current_group_name, current_sub_group))\n","            previous_sub_group = current_sub_group\n","            current_sub_group = []\n","\n","            if char == \")\":\n","                current_sub_group.append(i)\n","\n","            current_group_ascii += 1\n","            current_group_name = chr(current_group_ascii)\n","        else:  # wanted character types to represent a subgroup\n","            current_sub_group.append(i)  # add index of char to list\n","            index_to_group_dict[i] = [current_group_name]\n","\n","        if i + 1 == SMILES_length:  # for items at the very end of the string\n","            # leave as a list for now\n","            subgroup_index_list.append((current_group_name, current_sub_group))\n","\n","    subgroup_index_list = clean_subgroup_index_list(subgroup_index_list, SMILES_string)\n","    return subgroup_index_list\n","\n","def clean_subgroup_index_list(subgroup_index_list: list, SMILES_string: str) -> list:\n","    \"\"\"\n","    Input: subgroup_index_list is a list of lists of subgroup indices\n","    Output: subgroup_index_list with empty index tuples and single item tuples of non atoms removed\n","    \"\"\"\n","\n","    groups_to_remove = []\n","    for subgroup_tuple in subgroup_index_list:\n","        tuple_of_indices = subgroup_tuple[1]  # index 0 is the group name\n","        if not isinstance(tuple_of_indices, list):\n","            print(f\"Error: Expected list, got {type(tuple_of_indices)} at {subgroup_tuple}\")\n","        length_tuple_of_indices = len(tuple_of_indices)\n","\n","        if length_tuple_of_indices == 0:\n","            groups_to_remove.append((subgroup_tuple))\n","\n","        elif length_tuple_of_indices == 1 and (not SMILES_string[tuple_of_indices[0]].isalpha()):  # remove any unhelpful single item tuples\n","            groups_to_remove.append((subgroup_tuple))\n","\n","    for bad_group in groups_to_remove:\n","        subgroup_index_list.remove(bad_group)\n","    return subgroup_index_list\n","\n","\n","def create_group_dict(subgroup_index_list: list) -> dict:\n","    \"\"\"\n","    Input: subgroup_index_list is a list of lists representing all groups. Each interior list contains the\n","           group's symbol at [0] and indices list at [1]\n","    Output: dictionary in the format {group_symbol: [[group_symbol, [group_indices]], [empty neighbor_list]]}\n","    \"\"\"\n","\n","    subgroup_dict = {}\n","    for subgroup in subgroup_index_list:\n","        subgroup_dict[subgroup[0]] = [subgroup, []] # empty second list will hold neighbors\n","    return subgroup_dict\n","\n","\n","\n","def grouping_bridges_dict(SMILES_string: str) -> dict:\n","    \"\"\"\n","    Input: Smiles string\n","    Output: list of the index BEFORE starting parens, and index AFTER after corresponding end parens\n","    Ex Input: \"Cc(c(o)ccccc)C\"\n","    Ex Output: {2: 12, 4: 6}\n","    \"\"\"\n","    len_smiles_string = len(SMILES_string)\n","    group_bridge_dict = {}\n","    for i in range(len_smiles_string):\n","        char = SMILES_string[i]\n","\n","        if char == \"(\":\n","\n","            paren_num = 1\n","            start_paren_index = i\n","            for index in range(i + 1, len_smiles_string):\n","                current_char = SMILES_string[index]\n","\n","                if current_char == \"(\":\n","                    paren_num += 1\n","                elif current_char == \")\":\n","                    paren_num -= 1\n","\n","                if paren_num == 0 and current_char == \")\":\n","                    end_paren_index = index\n","                    group_bridge_dict[start_paren_index] = end_paren_index\n","                    break\n","\n","    return group_bridge_dict\n","\n","\n","\n","def determine_group_neighbors(SMILES_string: str, subgroup_index_list: list) -> dict:\n","    \"\"\"\n","    Input: SMILES_string is a string of the SMILES representation. subgroup_index_list is a list of lists of subgroup indices.\n","           subgroup_index_list should have been created by subgroups_from_SMILES()\n","    Output: dict mapping subgroups to adjacent/ overlapping subgroups. Connections are one directional. dict follows\n","            the format of {group_symbol: [[group_symbol, [group_indices]], [neighbor_list]]}\n","    \"\"\"\n","    group_bridge_dict = grouping_bridges_dict(SMILES_string)\n","    subgroup_dict = create_group_dict(subgroup_index_list)\n","    for this_subgroup in subgroup_index_list:\n","        this_subgroup_symbol = this_subgroup[0]\n","        this_subgroup_indices = this_subgroup[1]\n","\n","        for i in this_subgroup_indices:\n","            if i in group_bridge_dict:\n","                # if i is a key in this dict, then it is a start paren \"(\" index\n","                # \"(\" index maps to corresponding \")\" index\n","                bridged_index = group_bridge_dict[i]\n","\n","                # add to list so that this group, and the group originally containing the \")\" index are marked as neighbors\n","                this_subgroup_indices.append(bridged_index)\n","\n","\n","        for other_subgroup in subgroup_index_list:\n","\n","            for index in this_subgroup_indices:\n","                neighbor_index_back = index - 1\n","                neighbor_index_front = index + 1\n","\n","                other_subgroup_index_list = other_subgroup[1]\n","                other_subgroup_symbol = other_subgroup[0]\n","                other_subgroup_neighbors = subgroup_dict[other_subgroup_symbol][1]\n","\n","                if SMILES_string[index] == \")\":\n","                    continue\n","\n","                if neighbor_index_front in other_subgroup_index_list and SMILES_string[neighbor_index_front] == \")\":\n","                    continue\n","\n","                if this_subgroup_symbol == other_subgroup_symbol:\n","                    break\n","\n","                elif  this_subgroup_symbol in other_subgroup_neighbors:\n","                    # We want each neighbor connection to be one directional\n","                    # so that there are no duplicate tuples later on.\n","\n","                    break\n","\n","                elif (index in other_subgroup_index_list\n","                        or neighbor_index_back in other_subgroup_index_list\n","                        or neighbor_index_front in other_subgroup_index_list):\n","                    # Then they are neighbors\n","                    # Example subgroup: key -> [(key, [index_list]), [neighbor_symbol_list]\n","\n","                    subgroup_dict[this_subgroup_symbol][1].append(other_subgroup_symbol)\n","                    break # stop checking indices for current other_subgroup\n","\n","    return subgroup_dict\n","\n","\n","\n","def clean_subgroup_dict(subgroup_dict: dict, SMILES_string: str) -> dict:\n","    \"\"\"\n","    Input: subgroup_dict should have been created by determine_group_neighbors() and follows the format of\n","           {group_symbol: [[group_symbol, [group_indices]], [neighbor_list]]}, SMILES_string is a string\n","    Output: dict of the format {group_symbol: [group_string, [neighbor_symbols]]}\n","    \"\"\"\n","\n","    cleaned_subgroup_dict = {}\n","    for group_key in subgroup_dict:\n","        subgroup_info = subgroup_dict[group_key]\n","        group_neighbor_list = subgroup_info[1]\n","        group_index_list = subgroup_info[0][1]\n","\n","        # convert to characters\n","        group_string = \"\"\n","        is_ring = False # Special case for rings, we need a way to identify structures that are meant to represent rings\n","        for index in group_index_list:\n","            this_char = SMILES_string[index]\n","\n","            if this_char in [\"(\", \")\"]:\n","                continue\n","            elif this_char.isdigit():   # Don't want to include numbers in the end result, but we do need to include some sort of marker\n","                is_ring = True\n","                continue\n","            else:\n","                group_string += this_char\n","\n","        if is_ring:\n","            # 0 at index 0 will represent\n","            group_string = \"0\" + this_char\n","\n","        cleaned_subgroup_dict[group_key] = [group_string, group_neighbor_list]\n","\n","    return cleaned_subgroup_dict\n","\n","\n","\n","def get_group_list(cleaned_subgroup_dict: dict) -> tuple:\n","    \"\"\"\n","    Input: cleaned_subgroup_dict should have been created by clean_subgroup_dict() and follow the format\n","           {group_symbol: [group_string, [neighbor_symbols]]\n","    Output: list of all subgroups of the format [group_string_1, group_string_2, ... ]\n","    Note: subgroups that represent rings will have \"0\" at index 0 as a marker\n","    \"\"\"\n","\n","    group_list = []\n","    for group_key in cleaned_subgroup_dict:\n","        group_info = cleaned_subgroup_dict[group_key]\n","        group_string = group_info[0]\n","\n","        if len(group_string) == 0:\n","            continue\n","\n","        # add a \"0\" to the front of the string if it is a ring as a marker\n","        if type(group_key) == int:\n","            group_string = \"0\" + group_string\n","\n","        group_list.append(group_string)\n","\n","    return tuple(group_list)\n","\n","\n","\n","def create_group_combinations(cleaned_subgroup_dict: dict) -> tuple:\n","    \"\"\"\n","    Input: cleaned_subgroup_dict this dictionary should have already been processed by clean_subgroup_dict().\n","            Format should match {group_symbol: [group_string, [neighbor_symbols]]}\n","    Output: List of all possible combinations of adjacent subgroups\n","            Format follows tuple ((group_string_1, group_string_2, ... ]\n","\n","    Ex Output: (('CCCCCC', 'C'), ('[N+]', 'CCCCCC'), ('[N+]', '=O'), ('[O-]', '[N+]'), ('N', 'CCCCCC'))\n","    \"\"\"\n","\n","    group_combinations = []\n","\n","    for group_key in cleaned_subgroup_dict:\n","        this_group_info = cleaned_subgroup_dict[group_key]\n","        this_group_string = this_group_info[0]\n","        this_group_neighbors = this_group_info[1]\n","\n","        if this_group_string in [\"\", \"=\", \"#\"]:     # Unwanted groups\n","            continue\n","\n","        for neighbor_key in this_group_neighbors:\n","            other_group_info = cleaned_subgroup_dict[neighbor_key]\n","\n","            other_group_string = other_group_info[0]\n","\n","            # don't include these neighbors that escaped cleaning\n","            if other_group_string in [\"\", \"=\", \"#\"]:\n","                continue\n","\n","            group_combinations.append((this_group_string, other_group_string))\n","\n","    return tuple(group_combinations)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"joXkjp4YgHvz","executionInfo":{"status":"error","timestamp":1717828231603,"user_tz":420,"elapsed":241,"user":{"displayName":"Mateo","userId":"16385461059337377243"}},"outputId":"6ca5a4a7-bba5-497c-bc93-6344e5b56f90"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'ring_handling_w_rdkit'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-698cb090da80>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mring_handling_w_rdkit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mring_handle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msmiles_to_sub_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSMILES_string\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ring_handling_w_rdkit'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["**ring_handling_w_rdkit.py**\n","\n","Files that helps sub_group_from_smiles.py by handling cases were a smiles string contains a ring. When there is a ring, atoms must be treated as nodes in a map and more complex logic is needed. rdkit was used to pull these rings, and then more logic was used to convert the objects given into indexs of the string"],"metadata":{"id":"vwRWcnKlgPAz"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"0z7zjulzfujk","executionInfo":{"status":"error","timestamp":1717828240410,"user_tz":420,"elapsed":207,"user":{"displayName":"Mateo","userId":"16385461059337377243"}},"outputId":"961121ce-2a31-4bba-b5cb-8e6ba2ff1842"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'rdkit'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-4665292ad79c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrdmolops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from rdkit import Chem\n","from rdkit.Chem import rdmolops\n","\n","\n","\n","def ring_handling_rdkit(SMILES_string: str) -> list | bool:\n","    \"\"\"\n","    Input: SMILES_string is a string of the SMILES representation\n","    Output: list of lists of ring indices, returns False if there is an issue\n","    \"\"\"\n","\n","    molecule = Chem.MolFromSmiles(SMILES_string, sanitize=False)\n","\n","    if molecule is None:\n","        print(\"Invalid SMILES string.\")\n","        return False\n","    else:\n","        # Detect all rings in the molecule\n","        ring_vector = rdmolops.GetSymmSSSR(molecule, False)\n","        ring_idx_list = []\n","\n","        for ring in ring_vector:\n","            current_ring = []\n","            for idx in ring:\n","                current_ring.append(idx)\n","            ring_idx_list.append(current_ring)\n","\n","    idx_to_index_dict = map_idx_to_string_index(SMILES_string)\n","    ring_indices_list = []\n","    for ring_idxs in ring_idx_list:\n","        ring_indices = idx_to_index_of_rings(ring_idxs, idx_to_index_dict, SMILES_string)\n","\n","        ring_indices_list.append(ring_indices)\n","\n","    return ring_indices_list\n","\n","\n","\n","def map_idx_to_string_index(SMILES_string: str) -> dict:\n","    \"\"\"\n","    Input: SMILES_string is a string of the SMILES representation\n","    Output: returns a dictionary that maps IDX values to indices in the SMILES_string\n","    \"\"\"\n","\n","    idx = 0\n","    idx_to_index_dict = {}\n","    for index in range(len(SMILES_string)):\n","        character = SMILES_string[index]\n","        if character.isalpha():\n","            idx_to_index_dict[idx] = index\n","            idx += 1\n","\n","    return idx_to_index_dict\n","\n","\n","\n","def idx_to_index_of_rings(ring_idx_list: list, idx_to_index_dict: dict, SMILES_string: str) -> list:\n","    \"\"\"\n","    Input: ring_idx_list list of one ring's idx values. idx_to_index_dict dictionary\n","           that maps idx values to indices within the smiles string\n","    Output: list of indices of the ring\n","    \"\"\"\n","\n","    index_list = []\n","    for idx in ring_idx_list:\n","        index = idx_to_index_dict[idx]\n","        index_list.append(index)\n","\n","        if index < len(SMILES_string) and SMILES_string[index + 1] == \"(\":\n","            index_list.append(index + 1)\n","        if index - 1 >= 0 and SMILES_string[index - 1] == \")\":\n","            index_list.append(index - 1)\n","\n","    return index_list\n","\n","\n","\n","def create_dict_of_ring_indices(ring_indices_list: list) -> dict:\n","    \"\"\"\n","    Input: ring_indices_list created by ring_handling_rdkit\n","    Output: dict that maps indices of rings to their ring's respective ring_num\n","    \"\"\"\n","\n","    ring_index_dict = {}\n","    ring_num = 1\n","    for ring_index_list in ring_indices_list:\n","\n","        for i in ring_index_list:\n","            if i in ring_index_dict:\n","                ring_index_dict[i].append(ring_num)\n","            else:\n","                ring_index_dict[i] = [ring_num]\n","\n","        ring_num += 1\n","    return ring_index_dict"]},{"cell_type":"markdown","source":["## Creation of DataTables and Data Collection\n","\n","\n"],"metadata":{"id":"00U8CyerhP2U"}},{"cell_type":"markdown","source":["**Hazard_and_Subgroup_Column_Initialization.py**\n","\n","file used to create pd.DataFrames in the format needed for proper study of the data"],"metadata":{"id":"w-OE7X8uhT8X"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","import hashlib\n","\n","import sub_groups_from_smiles as subgroups\n","import Data_Collection_from_Pubchem as pubchem_coll\n","\n","import warnings\n","\n","# Suppress the specific PerformanceWarning from pandas\n","# These performance errors will be looked into in the future, but for now it works\n","warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n","warnings.simplefilter('ignore', category=pd.errors.SettingWithCopyWarning)\n","# this gets raised by .applymap(), but the version of pandas on google collab crashes using .map()\n","warnings.simplefilter('ignore', category=FutureWarning)\n","\n","\n","\n","def create_dataframe_from_cids(compound_IDs: list,\n","                              save_to_csv: bool=True, csv_name: str= 'compound_data.csv', wait_time: float=1,\n","                              drop_empty_hazard_rows: bool=True) -> pd.DataFrame|bool:\n","    \"\"\"\n","    Input: compound_IDs list of ints representing compound IDs. save_to_csv bool to determine whether to\n","           save dataframe to csv or not, default is True. wait_time is a float value of the desired wait time between\n","           requests in seconds. drop_empty_hazard_rows is a bool that is True by default. drops rows in the columns that\n","           do not have any hazard data associated with them. This is due to the inability to differentiate between\n","           chemicals that have no hazards because they are safe and chemicals that have no hazards because there simply\n","           is not enough data.\n","    Output: pd.DataFrame of compound data including a column for each type of hazard, and columns of group\n","            and group combination hash keys\n","    \"\"\"\n","\n","    try:\n","        # List of compound identifiers\n","        all_data = []\n","\n","        # Loop through each compound ID and fetch data\n","        for compound_ID in compound_IDs:\n","            try:\n","                compound_data = pubchem_coll.fetch_compound_data(compound_ID, wait_time)\n","            except KeyError:\n","                continue\n","\n","            all_data.append(compound_data)\n","\n","        df = pd.DataFrame(all_data)\n","\n","        # Collect grouping data\n","        initialize_grouping_data(df)\n","\n","        # Removes rows that don't have any hazards attached. Currently, there is no way to differentiate\n","        # between that chemicals that are safe, and chemicals that simply do not have any hazard data.\n","        if drop_empty_hazard_rows:\n","            df = df[df['Hazards'] != '']\n","\n","        # Save for later use\n","        if save_to_csv:\n","            df.to_csv(csv_name, index=False)\n","        columns_to_remove = [\"smiles_group_hash_list\", \"smiles_group_combination_hash_list\"]\n","        df = df.drop(columns=columns_to_remove, errors='ignore')\n","\n","        return df\n","    except ValueError:\n","        return False\n","\n","\n","\n","def generate_grouping_hash_lists_from_df(df: pd.DataFrame,\n","                                         Canonical_SMILES_column_name: str=\"Canonical SMILES\",\n","                                         create_columns: bool=True) -> bool:\n","    \"\"\"\n","    Input: df is a pd.DataFrame including a column of Canonical SMILES strings. Canonical_SMILES_column_name is the\n","           column name of the column containing the Canonical SMILES strings, it is \"Canonical SMILES\" by default.\n","           create_columns is a bool that determines if the columns \"smiles_group_hash_list\",\n","           \"smiles_group_combination_hash_list\", and \"could_not_collect_grouping_data\" need to be initialized.\n","           create_columns is True by default\n","    Output: bool that is True if columns were successfully created and/or updated to include hash lists, False\n","            otherwise\n","    \"\"\"\n","\n","    try:\n","        if create_columns:\n","            df[\"smiles_group_hash_list\"] = [[] for _ in range(len(df))]\n","            df[\"smiles_group_combination_hash_list\"] = [[] for _ in range(len(df))]\n","            df[\"could_not_collect_grouping_data\"] = 0\n","\n","        for index, row in df.iterrows():\n","            canonical_smiles = row[Canonical_SMILES_column_name]\n","\n","            group_hash_lists = generate_grouping_hash_lists_from_SMILES_string(canonical_smiles)\n","\n","            if group_hash_lists == False:\n","                df.at[index, \"could_not_collect_grouping_data\"] = 1\n","                continue\n","\n","            smiles_group_hash_list = group_hash_lists[0]\n","            smiles_group_combination_hash_list = group_hash_lists[1]\n","\n","            df.at[index, \"smiles_group_hash_list\"] = smiles_group_hash_list\n","            df.at[index, \"smiles_group_combination_hash_list\"] = smiles_group_combination_hash_list\n","\n","        return True\n","    except ValueError:\n","        return False\n","\n","\n","\n","def generate_grouping_hash_lists_from_SMILES_string(canonical_smiles: str) -> tuple|bool:\n","    \"\"\"\n","    Input: canonical_smiles of type str\n","    Output: tuple containing a hashlist of the different subgroups at index 0, and a hashlist of the different subgroup\n","            combinations at index 1. False if no subgroups could be pulled\n","    \"\"\"\n","    group_list_info = subgroups.smiles_to_sub_groups(canonical_smiles)\n","\n","    # group data could not be pulled\n","    if not group_list_info:\n","        return False\n","\n","    group_list = group_list_info[0]\n","    group_combination_list = group_list_info[1]\n","\n","    smiles_group_hash_list = []\n","    smiles_group_combination_hash_list = []\n","\n","    # get data for individual groups\n","    for group in group_list:\n","        group_hash_key = hash_smiles_group(group)\n","        smiles_group_hash_list.append(group_hash_key)\n","\n","    # get data for group combinations\n","    for group_combo in group_combination_list:\n","        group_combo_hash_key = hash_smiles_group_combination(group_combo)\n","        smiles_group_combination_hash_list.append(group_combo_hash_key)\n","\n","    return smiles_group_hash_list, smiles_group_combination_hash_list\n","\n","\n","\n","def convert_smiles_to_dataframe(canonical_smiles: str) -> pd.DataFrame:\n","    \"\"\"\n","    Input: canonical_smiles is a string.\n","    Output: A pd.DataFrame with only one row referring to canonical_smiles. pd.Dataframe contains columns of the\n","            hashed subgroups and subgroup combinations\n","    \"\"\"\n","\n","    hash_dict = {}\n","    hash_lists = generate_grouping_hash_lists_from_SMILES_string(canonical_smiles)\n","    hash_lists_combined = hash_lists[0] + hash_lists[1]\n","    for hash in hash_lists_combined:\n","        if hash in hash_dict:\n","            hash_dict[hash][0] += 1\n","        else:\n","            hash_dict[hash] = [1]\n","\n","    df = pd.DataFrame(hash_dict)\n","\n","    return df\n","\n","\n","\n","def fit_dataframes(this_smiles_df: pd.DataFrame, cleaned_main_df: pd.DataFrame) -> tuple:\n","    \"\"\"\n","    Input: this_smiles_df is a pd.DataFrame. cleaned_main_df is a pd.DataFrame\n","    Output: tuple containing this_smiles_df at index 0 and cleaned_main_df where both dataframes have each other's\n","            columns added and set to zero. Both DataFrames have the same columns and are in the same order\n","    \"\"\"\n","\n","    # ensure all columns are strings\n","    this_smiles_df.columns = this_smiles_df.columns.astype(str)\n","    cleaned_main_df.columns = cleaned_main_df.columns.astype(str)\n","\n","    # removes all columns not in this_smiles_df that are sum to less than 2\n","    cleaned_filtered_main_df = filter_columns_by_sum_and_input(main_df=cleaned_main_df, second_df=this_smiles_df)\n","\n","    # Get the common columns between this_smiles_df and cleaned_main_df\n","    common_columns = this_smiles_df.columns.intersection(cleaned_main_df.columns)\n","\n","    # Only keep the common columns in this_smiles_df\n","    this_smiles_df = this_smiles_df[common_columns]\n","\n","    # Add missing columns from cleaned_filtered_main_df to this_smiles_df and set their values to zero\n","    missing_columns = [col for col in cleaned_filtered_main_df.columns if col not in this_smiles_df.columns]\n","    for col in missing_columns:\n","        this_smiles_df[col] = 0\n","\n","    this_smiles_df = this_smiles_df[cleaned_filtered_main_df.columns]\n","    # Reorder the columns of this_smiles_df to match cleaned_main_df\n","\n","    return (this_smiles_df, cleaned_filtered_main_df)\n","\n","\n","\n","def hash_smiles_group(subgroup: str,\n","                      rotation_matters: bool=False) -> int|bool:\n","    \"\"\"\n","    Input: subgroup is string representation of a subgroup. These should have been\n","           created by subgroups.smiles_to_sub_groups(). rotation_matters is a bool that represents whether\n","           groups other than rings that maintain the same order but are shifted can map to the same group, is False by\n","           default\n","    Output: hash representing the input subgroup\n","\n","    Ex rotation_matters: if False, \"ABCDE\" and \"DEABC\" will map to the same hash and thus be counted as the same\n","                        group. If True, they will map to different hash. Regardless of rotation_matters,\n","                        \"0ABCDE\" and \"0DEABC\" will map to the same hash as they both represent a ring of the same\n","                        components in the same order. The \"0\" at index 0 marks the subgroup as a ring.\n","    \"\"\"\n","\n","    # check if subgroup is empty\n","    if subgroup == \"\":\n","        return False\n","\n","    is_ring = False\n","    if subgroup[0] == \"0\":\n","        is_ring = True\n","        subgroup = subgroup[1:]\n","\n","    if not rotation_matters or is_ring:\n","        rotations = [subgroup[i:] + subgroup[:i] for i in range(len(subgroup))]\n","        pre_hashed_key = str(is_ring) + min(rotations)\n","\n","    else:\n","        pre_hashed_key = str(is_ring) + subgroup\n","\n","    hashed = consistent_hash(pre_hashed_key)\n","\n","    return str(hashed)\n","\n","\n","\n","def hash_smiles_group_combination(group_combo: tuple,\n","                                  rotation_matters: bool=False) -> int:\n","    \"\"\"\n","    Input: group_combo is a tuple of length two containing two subgroups of the same molecule. These should have been\n","           created by subgroups.smiles_to_sub_groups(). rotation_matters is a bool that is False by default.\n","           rotation_matters determines whether non ring subgroups with the same elements and the same order, but are\n","           shifted, represent the same subgroup.\n","    Output: Hash code to represent the subgroup combination\n","    \"\"\"\n","\n","    group_1_hash = hash_smiles_group(group_combo[0], rotation_matters)\n","    group_2_hash = hash_smiles_group(group_combo[1], rotation_matters)\n","\n","    pre_hashed_key = min((group_1_hash + group_2_hash), (group_2_hash + group_1_hash))\n","    hashed_key = consistent_hash(pre_hashed_key)\n","\n","    return str(hashed_key)\n","\n","\n","\n","def create_grouping_columns(df: pd.DataFrame,\n","                            group_hashs_list_column_name: str=\"smiles_group_hash_list\") -> bool:\n","    \"\"\"\n","    Input: df is a pd.DataFrame containing a column that contains a list of subgroup hash's\n","    Output: bool of True if df was successfully mutated to include and update subgroup hash columns, False otherwise\n","    \"\"\"\n","\n","    try:\n","        for index, row in df.iterrows():\n","            hash_keys = row[group_hashs_list_column_name]\n","\n","            # For each hash key in the list\n","            for hash_key in hash_keys:\n","                # Check if the column exists\n","\n","                if hash_key in df.columns:\n","                    # Increment the value in the existing column\n","                    df.at[index, hash_key] += 1\n","\n","                else:\n","                    # Create a new column and initialize it\n","                    df[hash_key] = 0  # Initialize the new column with zeros\n","                    df.at[index, hash_key] = 1\n","\n","    except ValueError:\n","        return False\n","\n","\n","\n","def initialize_grouping_data(df: pd.DataFrame,\n","                             Canonical_SMILES_column_name: str = \"Canonical SMILES\") -> bool:\n","    \"\"\"\n","    Input: DataFrame containing a column with Canonical SMILES strings. Canonical_SMILES_column_name is the name\n","           of the column containing the Canonical SMILES representations.\n","    Output: True if df was successfully mutated to include hazard columns and subgroup columns, False otherwise\n","    \"\"\"\n","\n","    try:\n","        split_hazard_data(df)\n","        generate_grouping_hash_lists_from_df(df, Canonical_SMILES_column_name)\n","        create_grouping_columns(df)\n","        return True\n","    except ValueError:\n","        return False\n","\n","\n","\n","def split_hazard_data(df: pd.DataFrame,\n","                      hazard_column_name: str=\"Hazards\") -> bool:\n","    \"\"\"\n","    Input: pd.DataFrame containing a column that contains compound hazards\n","    Output: True if df was successfully mutated to include a column for each type of hazard, False otherwise\n","    \"\"\"\n","\n","    try:\n","        for index, row in df.iterrows():\n","            hazards_string = row[hazard_column_name]\n","            if type(hazards_string) != str:\n","                continue\n","\n","            hazard_list = re.sub(r'\\s+', '', hazards_string).split(\",\")\n","\n","            # For each hazard in the list\n","            for hazard in hazard_list:\n","\n","                # Check if the column exists\n","                if hazard in df.columns:\n","                    # Set row value to True\n","                    df.at[index, hazard] = 1\n","\n","                else:\n","                    # Create a new column and initialize it\n","                    df[hazard] = 0  # Initialize the new column with 0 to represent False\n","                    df.at[index, hazard] = 1   # set this row's value to 1 to represent True\n","\n","        return True\n","    except ValueError:\n","        return False\n","\n","\n","\n","def update_existing_ids_dataframe_from_cids(main_df: pd.DataFrame, new_compound_IDs: list,\n","                                            save_to_csv: bool=True, csv_name: str=\"compound_data.csv\",\n","                                            overwrite_old_data: bool=False) -> pd.DataFrame|bool:\n","    \"\"\"\n","    Input: main_df is a pd.DataFrame that will be mutated to include new data. new_compound_IDS is list of ints\n","           representing compound IDs.  save_to_csv bool to determine whether to\n","           save dataframe to csv or not, default is True. overwrite_old_data is a bool that determine whether data for\n","           old compound IDs can\n","           be overwritten by new data. overwrite_old_data is False by default\n","    Output: The merged pd.DataFrame if parent_dataframe was successfully mutated to include new compound IDs, False\n","            otherwise\n","    \"\"\"\n","\n","    try:\n","        new_df = create_dataframe_from_cids(new_compound_IDs, save_to_csv=False)\n","\n","    except ValueError:\n","        print(\"Issue with new compound IDs\")\n","        return False\n","\n","    try:\n","        return update_existing_dataframe_from_dataframe(main_df, new_df, save_to_csv=save_to_csv, csv_name=csv_name, overwrite_old_data=overwrite_old_data)\n","\n","    except ValueError:\n","        print(\"Issue combining dataframes\")\n","        return False\n","\n","\n","\n","def update_existing_dataframe_from_dataframe(main_df: pd.DataFrame, second_df: pd.DataFrame,\n","                                             save_to_csv: bool=True, csv_name: str=\"compound_data.csv\",\n","                                             overwrite_old_data: bool=False) -> pd.DataFrame|bool:\n","    \"\"\"\n","    Input: main_df is a pd.DataFrame that will be mutated to include new data. second_df is a pd.DataFrame that will be\n","           used to update main_df. save_to_csv bool to determine whether to save dataframe to csv or not, default is\n","           True. overwrite_old_data is a bool that determine whether data for old compound IDs can be overwritten by\n","           new data. overwrite_old_data is False by default\n","    Output: The merged pd.DataFrame if parent_dataframe was successfully mutated to include new compound IDs, False\n","            otherwise\n","    \"\"\"\n","\n","    try:\n","        if \"Compound ID\" not in main_df.columns or \"Compound ID\" not in second_df.columns:\n","            raise ValueError(\"Both dataframes must have a 'Compound ID' column\")\n","\n","        if overwrite_old_data:\n","\n","            matching_ids = second_df[\"Compound ID\"].isin(main_df[\"Compound ID\"])\n","            matching_rows = second_df[matching_ids]\n","\n","            # this is what will be iterated over to add missing columns\n","\n","            second_df = second_df[~matching_ids]\n","            main_df = main_df.set_index(\"Compound ID\")\n","            matching_rows = matching_rows.set_index(\"Compound ID\")\n","            main_df.update(matching_rows)\n","            main_df = main_df.reset_index()\n","\n","        else:\n","            # filters out rows in second_df that have matching \"Compound ID\" with values in main_df\n","            second_df = second_df[~second_df[\"Compound ID\"].isin(main_df[\"Compound ID\"])]\n","\n","        # Step 1: Add missing columns from main_df to second_df and set them to 0\n","        for col in main_df.columns:\n","            if col not in second_df.columns:\n","                second_df.loc[:, col] = 0\n","\n","        # Step 2: Add missing columns from second_df to main_df and set them to 0\n","        for col in second_df.columns:\n","            if col not in main_df.columns:\n","                main_df.loc[:, col] = 0\n","\n","        # Step 3: Ensure both dataframes have the same columns and order\n","        main_df = main_df[sorted(main_df.columns, key=str)]\n","        second_df = second_df[sorted(second_df.columns, key=str)]\n","\n","        # Step 4: Concatenate the dataframes\n","        combined_df = pd.concat([main_df, second_df], ignore_index=True)\n","\n","        if save_to_csv:\n","            combined_df.to_csv(csv_name, index=False)\n","\n","        return combined_df\n","\n","    except ValueError:\n","        print(\"Issue combining dataframes\")\n","        return False\n","\n","\n","\n","def filter_columns_by_sum_and_input(main_df: pd.DataFrame, second_df: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Input: main_df is a pd.DataFrame, second_df pd.DataFrame\n","    Output: updated main_df that contains only columns that have more than one \"1\" or are present in second_df\n","    \"\"\"\n","    columns_to_keep = []\n","    for col in main_df.columns:\n","        if main_df[col].sum() >= 2 or (col in second_df.columns):\n","            columns_to_keep.append(col)\n","    return main_df[columns_to_keep]\n","\n","\n","\n","def add_hazard_and_hash_columns_from_csv(csv_name: str,\n","                                         drop_empty_hazard_rows: bool=True,\n","                                         save_to_csv: bool=True,\n","                                         ) -> pd.DataFrame|bool:\n","\n","    try:\n","        df = pd.read_csv(csv_name)\n","\n","        # Collect grouping data\n","        initialize_grouping_data(df)\n","\n","        # Removes rows that don't have any hazards attached. Currently, there is no way to differentiate\n","        # between that chemicals that are safe, and chemicals that simply do not have any hazard data.\n","        if drop_empty_hazard_rows:\n","            df = df[df['Hazards'] != '']\n","\n","        # Save for later use\n","        if save_to_csv:\n","            df.to_csv(csv_name, index=False)\n","        columns_to_remove = [\"smiles_group_hash_list\", \"smiles_group_combination_hash_list\"]\n","        df = df.drop(columns=columns_to_remove, errors='ignore')\n","\n","        return df\n","\n","    except ValueError:\n","        return False\n","\n","\n","\n","def consistent_hash(input_string):\n","    \"\"\"\n","    Input: input_string is a string.\n","    Output: hash representing input_string. Hash is consistently calculated\n","    \"\"\"\n","    # Create a hashlib md5 hash object\n","    hash_object = hashlib.md5(input_string.encode())\n","    # Generate a hash value in hexadecimal format\n","    return hash_object.hexdigest()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"XSyd2UR5hA-i","executionInfo":{"status":"error","timestamp":1717828685550,"user_tz":420,"elapsed":818,"user":{"displayName":"Mateo","userId":"16385461059337377243"}},"outputId":"c93f56c4-337a-4d8b-e364-ad0438450d08"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'sub_groups_from_smiles'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-a78e8fea5b36>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0msub_groups_from_smiles\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msubgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData_Collection_from_Pubchem\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpubchem_coll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sub_groups_from_smiles'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","source":["**Data_Collection_from_Pubchem.py**\n","File used to collect data from Pubhcem pug_view API to be used to instantiate pd.DataFrames"],"metadata":{"id":"ZxtNKFDoiCUO"}},{"cell_type":"code","source":["import requests\n","import time\n","\n","\n","\n","def fetch_compound_data(compound_ID: int, wait_time: float=1.5) -> dict:\n","    \"\"\"\n","    Input: compound_ID is an int representation of the compound ID. wait_time is a float value of the desired\n","    wait time between requests in seconds. wait_time is 1.5 seconds by default\n","    Output: dictionary containing compound info including Canonical Smiles, and Hazards\n","    \"\"\"\n","\n","    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/{compound_ID}/JSON/\"\n","    response = requests.get(url, timeout=10)\n","\n","    try:\n","        data = response.json()\n","    except ValueError:\n","        return None\n","\n","    if 'Record' not in data:\n","        return None\n","\n","    # cool down inbetween calls\n","    time.sleep(wait_time)\n","\n","    data = response.json()\n","\n","    iupac_name = None\n","    canonical_smiles = None\n","    hazards = []\n","\n","    # Extracting IUPAC name and canonical SMILES\n","    for section in data['Record']['Section']:\n","        if section['TOCHeading'] == 'Names and Identifiers':\n","            for subsection in section['Section']:\n","                if subsection['TOCHeading'] == 'Computed Descriptors':\n","                    for descriptor in subsection['Section']:\n","                        if descriptor['TOCHeading'] == 'IUPAC Name':\n","                            iupac_name = descriptor['Information'][0]['Value']['StringWithMarkup'][0]['String']\n","                        elif descriptor['TOCHeading'] == 'Canonical SMILES':\n","                            canonical_smiles = descriptor['Information'][0]['Value']['StringWithMarkup'][0]['String']\n","\n","    # Extracting hazards\n","    for section in data['Record']['Section']:\n","        if section['TOCHeading'] == 'Safety and Hazards':\n","            for subsection in section['Section']:\n","                if subsection['TOCHeading'] == 'Hazards Identification':\n","                    for subsubsection in subsection['Section']:\n","                        if subsubsection['TOCHeading'] == 'GHS Classification':\n","                            for info in subsubsection['Information']:\n","                                if info['Name'] == 'Pictogram(s)':\n","                                    for pictogram in info['Value']['StringWithMarkup'][0]['Markup']:\n","                                        hazards.append(pictogram['Extra'])\n","\n","    return {\n","        \"Compound ID\": compound_ID,\n","        \"IUPAC Name\": iupac_name,\n","        \"Canonical SMILES\": canonical_smiles,\n","        \"Hazards\": ', '.join(hazards)\n","    }"],"metadata":{"id":"RoGD611ciC85"},"execution_count":null,"outputs":[]}]}